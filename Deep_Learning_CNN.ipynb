{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c137da0",
   "metadata": {},
   "source": [
    "# DVA263 - Applied Machine Learning\n",
    "\n",
    "### Exercise\n",
    "\n",
    "This exercise involves the development of an Convolutional Neural Network (CNN) that classifies handwritten digits from the MNIST dataset. The task will require preprocessing the data, constructing the network, and then training the model to recognize digit images.\n",
    "\n",
    "<span style=\"color:red\">Note:</span>\n",
    "Please make sure that the system have following packages installed before doing the exercise.\n",
    "* Numpy\n",
    "* Tensorflow\n",
    "* Scikit-learn\n",
    "* Matplotlib\n",
    "* Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb9054",
   "metadata": {},
   "source": [
    "# *Libraries*\n",
    "\n",
    "Libraries have already been declared. Please declare any additional libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "id": "27fb1559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.277720Z",
     "start_time": "2024-12-30T13:00:19.273601Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "d2b0a4ca",
   "metadata": {},
   "source": [
    "# *Load the MNIST Dataset*\n",
    "\n",
    "The MNIST dataset consists of 60,000 images for training and 10,000 images for testing, all of which contain handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "id": "dd951af7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.314366Z",
     "start_time": "2024-12-30T13:00:19.308477Z"
    }
   },
   "source": [
    "# This function is for loading the MNIST handwritten dataset.\n",
    "# You do not have to change anything.\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    return x_train, y_train, x_test, y_test"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "4b179abe",
   "metadata": {},
   "source": [
    "# *Plot First Ten Images*\n",
    "\n",
    "Plotting images will help to understand the how each image looks like"
   ]
  },
  {
   "cell_type": "code",
   "id": "9194f8b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.350703Z",
     "start_time": "2024-12-30T13:00:19.346Z"
    }
   },
   "source": [
    "# This function is for visualize first 10 image.\n",
    "# You do not have to change anything.\n",
    "\n",
    "def plot_first_ten_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "b08b00f2",
   "metadata": {},
   "source": [
    "# *Prepare Final Data*\n",
    "\n",
    "Prepare the dataset for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "id": "ac3dd629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.359755Z",
     "start_time": "2024-12-30T13:00:19.352709Z"
    }
   },
   "source": [
    "def prepare_data(x_train, y_train, x_test, y_test): # Insert parameters name \n",
    "    \n",
    "    # Please perform following tasks to prepare final data\n",
    "    \n",
    "    \n",
    "    \"\"\"------------ Task 1 - Normalization -------------\n",
    "    Instruction:\n",
    "        - Normalize the pixel values of the images from the range [0, 255] to [0, 1] for both training and test sets. \n",
    "        - This is done by dividing by the maximum value of a pixel, which is 255.\n",
    "        - Store the normalized data in \"x_train\" and \"x_test\".\n",
    "    \"\"\"\n",
    "    x_train = x_train/255\n",
    "    x_test = x_test/255\n",
    "\n",
    "    \"\"\"------------- Task 2 - Reshape Images -----------\n",
    "     Instruction:\n",
    "        - Reshape the images to include a channel dimension, going from (28, 28) to (28, 28, 1),\n",
    "        - because the CNN expects three-dimensional inputs (height, width, channels).\n",
    "        - Store the reshaped data again in \"x_train\" and \"x_test\".\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "    x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "    \"\"\"------------- Task 3 - One-Hot Encoding ----------\n",
    "    Instruction:\n",
    "        - Convert the categorical integer labels into a binary matrix representation using one-hot encoding.\n",
    "        - This step is crucial for classification tasks to properly format the labels for the output layer of the network.\n",
    "        - Store the one-hot encoding data in \"y_train\" and \"y_test\".\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "    y_test = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    \"\"\"--------- Task 4 - After these preprocessing steps, the function will return four variables---------\n",
    "        - \"x_train\": the reshaped training features\n",
    "        - \"y_train\": the one-hot encoded training labels\n",
    "        - \"x_test\": the reshaped testing features\n",
    "        - \"y_test\": the one-hot encoded testing labels\n",
    "    \"\"\"\n",
    "    return  x_train, y_train, x_test, y_test"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "f63c170f",
   "metadata": {},
   "source": [
    "# *Build CNN Model*\n",
    "\n",
    "Build the CNN model using hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "id": "a6826cba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.376964Z",
     "start_time": "2024-12-30T13:00:19.372296Z"
    }
   },
   "source": [
    "\"\"\"---- Task - Define your Convolutional Neural Network (CNN) Architecture inside the \"build_cnn_model()\" function----\n",
    "\n",
    "Instruction:\n",
    "    - Use the Sequential model from Keras to stack layers in a linear format.\n",
    "    - Start with convolutional layer where 'input_shape' should be set to (28, 28, 1) to match the shape of the MNIST images.\n",
    "    - It's ideal to start with a kernel filter size of (3, 3) and explore using more filters as needed.\n",
    "    - Use necessary activation function in each layer.\n",
    "    - Use max pooling layers to reduce the spatial dimensions of your output volume after the convolutional layers.\n",
    "    - Use a flatten layer to transform the 2D feature maps into a 1D feature vector before feeding it into the dense layer.\n",
    "    - Continue adding dense layers reducing the number of neurons in each subsequent layer.\n",
    "    - Apply L2 regularization if necessary to the layer to help prevent overfitting during training.\n",
    "    - Add dropout after dense layers if necessary to further prevent overfitting during training.\n",
    "    - Finish with a Dense output layer with 10 units and a 'softmax' activation to handle the multi-class classification, \n",
    "    - where each unit corresponds to one of the ten classes of the MNIST digits (0-9).\n",
    "\"\"\" \n",
    "\n",
    "def build_cnn_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "8c2982fc",
   "metadata": {},
   "source": [
    "# *Compile and Train the Model*\n",
    "\n",
    "Compile and traning the build model. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.410024Z",
     "start_time": "2024-12-30T13:00:19.402993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"------Compile and train the model by using the \"compile_and_train()\" function.------ \n",
    "Instruction:\n",
    "    - The function consits of three tasks where one is optional.\n",
    "    - We appriciate if you perform the optional task.\n",
    "    - Task 1 related to use of compile function. It has few hyperparametrs those are important\n",
    "    - to configure the learning process of the model.\n",
    "    - Task 2 related to use of fit function. It has few hyperparametrs those are important to train the model using dataset.\n",
    "    - In the Task optional, \"callbacks[]\" used to perform actions such as saving the model weights,\n",
    "    - logging training metrics, or stopping the training process early if the model is not improving.\n",
    "\"\"\"\n",
    "\n",
    "def compile_and_train(model, x_train, y_train): # Insert parameters name \n",
    "    \n",
    "    \"\"\"----- Optional Task - Declare callbacks.-----\n",
    "    Instruction:\n",
    "        - Uncomment \"callbacks[]\" if it is necessary.\n",
    "        - Use only \"EarlyStopping()\" or \"ReduceLROnPlateau()\" or both functions.\n",
    "        - Write necessary hyperparameters inside the function.\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    \n",
    "    \n",
    "    # End optional task\n",
    "\n",
    "    \"\"\"----- Task 1 - Compile Function.------\n",
    "    Instruction:\n",
    "        - Use compile function write all the necessary hyperparameters inside the complie function.\n",
    "        - For example \"model.compile()\" where \"model\" already build using \"build_model()\" fucntion.\n",
    "    \"\"\"\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \"\"\"----- Task 2 - Fit Function.------\n",
    "    Instruction:\n",
    "        - Use fit function and write all the necessary hyperparameters inside the fit function.\n",
    "        - For example \"model.fit()\" where \"model\" already build using \"build_model()\" fucntion.\n",
    "        - Store the results after fitting the model in \"history\".\n",
    "        - Don't forget to split the dataset for validation.\n",
    "    \"\"\"\n",
    "    model.fit(x=x_train,y=y_train,epochs=100,validation_split=0.2)\n",
    "    \n",
    "    \n",
    "    return model.history"
   ],
   "id": "c8fe0d84ae336540",
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "d68b8454",
   "metadata": {},
   "source": [
    "# *Plotting Training and Validation Figures*\n",
    "\n",
    "Plot the training and validation loss and accuracy figures"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd9abe1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.465770Z",
     "start_time": "2024-12-30T13:00:19.458211Z"
    }
   },
   "source": [
    "# \"plot_metrics()\" function help to plot loss and accuracy figure of the training and validation.\n",
    "\n",
    "def plot_metrics(history): # Insert parameter name \n",
    "    \n",
    "    # Plot traning and validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot traning and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "4e7fbca8",
   "metadata": {},
   "source": [
    "# *Evaluate the Model and Plot the Confusion Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "id": "9eeaae75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.483566Z",
     "start_time": "2024-12-30T13:00:19.478289Z"
    }
   },
   "source": [
    "# \"evaluate_and_confusion_matrix()\" function display the evalutaion result after training and testing the model. \n",
    "\n",
    "def evaluate_and_confusion_matrix(model, x_train, y_train, x_test, y_test): # Insert parameters name \n",
    "    \n",
    "    # Predictions for the training set\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
    "    y_true_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "    # Predictions for the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate and print the training and test accuracy\n",
    "    train_accuracy = accuracy_score(y_true_train, y_train_pred_classes)\n",
    "    test_accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Calculate and print the F1 score for the test set\n",
    "    f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "c4624cdc",
   "metadata": {},
   "source": [
    "# *Main Section*\n",
    "\n",
    "The main section is responsible for calling all the functions, each of which has specific tasks to perform."
   ]
  },
  {
   "cell_type": "code",
   "id": "2ea429e9de2b3382",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:19.771612Z",
     "start_time": "2024-12-30T13:00:19.538261Z"
    }
   },
   "source": [
    "# --------------------------------------This is the main section------------------------------\n",
    "\n",
    "\"\"\"----- Task 1: Dataset loading------\n",
    "\n",
    "Instruction:\n",
    "    - Call the \"load_data()\" function to load the MNIST dataset. \n",
    "    - This function returns two tuples: one for the training data and another for the testing data.\n",
    "    - Each tuple contains a set of images and their corresponding labels.\n",
    "    - Store the images and labels in the following variables:\n",
    "    - x_train: training images\n",
    "    - y_train: training labels\n",
    "    - x_test: testing images\n",
    "    - y_test: testing labels\n",
    "\"\"\"\n",
    "x_train, y_train, x_test, y_test = load_data()"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:20.821604Z",
     "start_time": "2024-12-30T13:00:19.772630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"----- Task 2: First 10 Images Visualization------\n",
    "Instruction:\n",
    "    - Call the \"plot_first_ten_images()\" function to display the first ten images from the dataset.\n",
    "    - This function takes two arguments:\n",
    "    - 'images': a collection of image data, usually as an array where each element is an image.\n",
    "    - 'labels': the corresponding labels for each image, indicating the class or category of the image.\n",
    "    - The function creates a 1x10 grid of subplots, where each subplot will display one of the first ten images\n",
    "    - in 'grayscale' and title it with its corresponding label.\n",
    "\"\"\"\n",
    "plot_first_ten_images(x_train, y_train)"
   ],
   "id": "95c588be0da45efd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x200 with 10 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T13:00:32.429319Z",
     "start_time": "2024-12-30T13:00:20.822134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"----- Task 3: Prepare Datset--------\n",
    "Instruction:\n",
    "    - Call the \"prepare_data()\" function to perform preprocessing on the training and test datasets.\n",
    "    - This function will execute feature extraction, normalization, flattening, and one-hot encoding of labels.\n",
    "    - The output will be the prepared dataset, ready for training a neural network.\n",
    "    - You will receive four variables as a result:\n",
    "    - \"x_train_flat\": Training data features, flattened for the neural network input.\n",
    "    - \"y_train_encoded\": Training data labels, one-hot encoded.\n",
    "    - \"x_test_flat\": Test data features, similarly flattened.\n",
    "    - \"y_test_encoded\": Test data labels, one-hot encoded.\n",
    "\"\"\"\n",
    "x_train, y_train, x_test, y_test = prepare_data(x_train, y_train, x_test, y_test)\n",
    "\n",
    "\"\"\"----- Task 4: Build the model------\n",
    "Instruction:\n",
    "    - Call the \"build_model()\" function to initialize your artificial neural network model.\n",
    "    - The model returned is ready to be compiled and trained with your dataset.\n",
    "\"\"\"\n",
    "model = build_cnn_model()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----- Task 5: Compile and Train------\n",
    "Instruction:\n",
    "    - Call the \"compile_and_train()\" function to compile and train your neural network model.\n",
    "    - The function requires three arguments:\n",
    "    - 'model': The ANN model you previously built with the \"build_model()\" function.\n",
    "    - 'x_train_flat': The flattened feature data from your training set, prepared for neural network input.\n",
    "    - 'y_train_encoded': The one-hot encoded labels from your training set.\n",
    "    - This function will first compile the model with the necessary configurations and then fit the model on the training data.\n",
    "    - The output \"history\" object will contain information about the training process, such as loss and accuracy for each epoch.\n",
    "    - Execute the following line of code to start the compilation and training process:\n",
    "\"\"\"\n",
    "history = compile_and_train(model,x_train,y_train)"
   ],
   "id": "ab858e1e13efa08c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1157/1500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.8348 - loss: 0.8368"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[46], line 34\u001B[0m\n\u001B[0;32m     19\u001B[0m model \u001B[38;5;241m=\u001B[39m build_cnn_model()\n\u001B[0;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"----- Task 5: Compile and Train------\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;124;03mInstruction:\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;124;03m    - Call the \"compile_and_train()\" function to compile and train your neural network model.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;124;03m    - Execute the following line of code to start the compilation and training process:\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mcompile_and_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[41], line 39\u001B[0m, in \u001B[0;36mcompile_and_train\u001B[1;34m(model, x_train, y_train)\u001B[0m\n\u001B[0;32m     30\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     32\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"----- Task 2 - Fit Function.------\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03mInstruction:\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m    - Use fit function and write all the necessary hyperparameters inside the fit function.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;124;03m    - Don't forget to split the dataset for validation.\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mhistory\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:118\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    321\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[0;32m    322\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 323\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    324\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(\n\u001B[0;32m    325\u001B[0m         step, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[0;32m    326\u001B[0m     )\n\u001B[0;32m    327\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1324\u001B[0m     args,\n\u001B[0;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1326\u001B[0m     executing_eagerly)\n\u001B[0;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1498\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1500\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1501\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1503\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1504\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1505\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1506\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1508\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1509\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1510\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1514\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1515\u001B[0m   )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"----- Task 6: Plotting Training Metrics------\n",
    "Instruction:\n",
    "    - Call the \"plot_metrics()\" function to visualize the training and validation metrics.\n",
    "    - Pass the 'history' object, which contains the training history of the model, as an argument to the function.\n",
    "    - This function will generate plots for both the loss and accuracy of the model during training.\n",
    "    - It helps to assess the model's performance and to identify if the model is overfitting or underfitting.\n",
    "\"\"\"\n",
    "plot_metrics(history)\n",
    "\n",
    "\"\"\"----- Task 7: Model Evaluation and Confusion Matrix Visualization-----\n",
    "Instruction:\n",
    "    - Call the \"evaluate_and_confusion_matrix()\" function to evaluate the model's performance on both the training and testing data.\n",
    "    - This function will also plot the confusion matrix for the test data, providing insight into the model's classification accuracy across different classes.\n",
    "    - The function takes the following parameters:\n",
    "       - 'model': The trained ANN model.\n",
    "       - 'x_train_flat': The flattened training data features.\n",
    "       - 'y_train_encoded': The one-hot encoded training data labels.\n",
    "       - 'x_test_flat': The flattened testing data features.\n",
    "       - 'y_test_encoded': The one-hot encoded testing data labels.\n",
    "    - After execution, the function will display the training and test accuracy and plot the confusion matrix.\n",
    "\"\"\"\n",
    "evaluate_and_confusion_matrix(model,x_train,y_train,x_test,y_test)\n",
    "\n"
   ],
   "id": "78e45d73",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5209b020",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
